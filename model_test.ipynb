{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: failed to find module: moviepy.editor\n",
      "GPU Available:\t True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Script\n",
    "\n",
    "\"\"\"\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from vwgym import VacuumWorld, Vectorise, StepWrapper\n",
    "from vwgym.fun_lite import *\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.gymutils as gu\n",
    "\n",
    "random.seed(123518)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU Available:\\t', True)\n",
    "    device = 'cuda'\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'vwgym/saved_model/vwgym_f_net_last_checkpoint.pt'\n",
    "checkpoint = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = checkpoint['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_n = VacuumWorld(args['grid_size'])\n",
    "# env_v = Vectorise(copy.deepcopy(env_n))\n",
    "# env = StepWrapper(env_v)\n",
    "env, input_shape = make_env(args['grid_size'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = env[0].action_space.n\n",
    "input_dim = (3, 8, 8)\n",
    "f_net = FuNet(input_dim, args['d'], args['len_hist'], args['eps'], args['k'], num_actions, 1, device)\n",
    "optimizer = torch.optim.Adam(f_net.parameters(), lr=args['lr'], eps=1e-5)\n",
    "\n",
    "f_net.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FuNet(\n",
       "  (f_percept): Percept(\n",
       "    (conv_1): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv_2): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (fc_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (fc_2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (percept): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (flat): Flatten()\n",
       "  )\n",
       "  (manager): Manager(\n",
       "    (M_space): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (M_relu): ReLU()\n",
       "    (M_tanh): Tanh()\n",
       "    (M_goals): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (M_value): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (worker): Worker(\n",
       "    (f_stateW): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=32, out_features=80, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (phi): Linear(in_features=256, out_features=16, bias=False)\n",
       "    (f_valueW): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=20, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=20, out_features=1, bias=True)\n",
       "    )\n",
       "    (W_relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirts Present..:16\n",
      "\n",
      "Grid Cleaned !!\n",
      "\n",
      "{'ep_rewards': 165, 'ep_len': 3586, 'move': 769, 'clean': 668, 'turn_left': 713, 'turn_right': 705, 'idle': 731}\n",
      "Episode Rewards:\t 165\n",
      "reward = 165 \t| ep_score = 0.17\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    f_net.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    goal_history, s_Mt_hist, ep_binary = f_net.agent_model_init()\n",
    "    x = np.array([e.reset() for e in env])\n",
    "    \n",
    "    for e in env:\n",
    "        e.rw_dirts = e.dirts\n",
    "        print(f'Dirts Present..:{e.rw_dirts}')\n",
    "        \n",
    "    x = torch.from_numpy(x/255).float().to(device)\n",
    "    step = 0\n",
    "    prev_action = []\n",
    "    \n",
    "    for __ in range(5000):\n",
    "        action_probs, v_Mt, v_Wt, goal_history, s_Mt_hist = f_net(x, goal_history, s_Mt_hist)\n",
    "        a_t, _, _ = take_action(action_probs)\n",
    "        x, reward, done, ep_info = take_step(a_t, env, device)\n",
    "        for ep_d in ep_info:\n",
    "            if ep_d['ep_rewards'] is not None:\n",
    "                print(f\"reward = {round(ep_d['ep_rewards'], 2)} \\t| ep_score = {round(600/ep_d['ep_len'], 2)}\")\n",
    "        \n",
    "        if done[0]:\n",
    "            break\n",
    "        ep = torch.FloatTensor(1.0 - done).unsqueeze(-1).to(device)\n",
    "        ep_binary.pop(0)\n",
    "        ep_binary.append(ep)\n",
    "        predictions.append(a_t[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>action_meanings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>move</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idle</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turn_left</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turn_right</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  action_meanings\n",
       "0        move              769\n",
       "1        idle              731\n",
       "2   turn_left              713\n",
       "3  turn_right              705\n",
       "4       clean              667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.DataFrame.from_dict({'actions': predictions, 'action_meanings':[env[0].action_meanings[i] for i in predictions]})\n",
    "p['action_meanings'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(predictions))\n",
    "# predictions.append(4)\n",
    "# print(len(predictions))\n",
    "# print(env_v.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ac_1 = iter(predictions)\n",
    "# ac_2 = iter(predictions)\n",
    "\n",
    "# nstate = gu.episode(env_n, lambda _: next(ac_1), max_length=len(predictions))[0]\n",
    "# vstate = gu.episode(env_v, lambda _: next(ac_2), max_length=len(predictions))[0]\n",
    "\n",
    "# vis = np.concatenate([vstate[:,None,i] for i in [0,1,2]], axis=3)\n",
    "\n",
    "# J.images(vis, scale=40, on_interact=list(zip(np.array(env.action_meanings)[predictions],nstate)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
    "\n",
    "# a, b = torch.rand(1, 8), torch.rand(8, 5)\n",
    "\n",
    "# nn.functional.softmax(torch.mm(a, b))\n",
    "\n",
    "# import time\n",
    "\n",
    "# time.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
