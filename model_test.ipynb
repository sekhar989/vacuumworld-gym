{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: failed to find module: moviepy.editor\n",
      "GPU Available:\t True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Script\n",
    "\n",
    "\"\"\"\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from vwgym import VacuumWorld, Vectorise, StepWrapper\n",
    "from vwgym.fun_lite import *\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.gymutils as gu\n",
    "\n",
    "random.seed(123518)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU Available:\\t', True)\n",
    "    device = 'cuda'\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'vwgym/saved_model/vwgym_f_net_step_500000.pt'\n",
    "checkpoint = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = checkpoint['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_n = VacuumWorld(args['grid_size'])\n",
    "env_v = Vectorise(copy.deepcopy(env_n))\n",
    "env = StepWrapper(env_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = env.action_space.n\n",
    "input_dim = (3, 8, 8)\n",
    "f_net = FuNet(input_dim, args['d'], args['len_hist'], args['eps'], args['k'], num_actions, device)\n",
    "optimizer = torch.optim.Adam(f_net.parameters(), lr=args['lr'], eps=1e-5)\n",
    "\n",
    "f_net.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0 255   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0 128   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0 128   0 128]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [255   0   0 255 255   0   0   0]\n",
      "  [  0   0   0   0   0 255 128   0]\n",
      "  [128   0   0   0   0   0   0   0]\n",
      "  [255   0   0   0 128 128 255   0]\n",
      "  [  0   0   0 128 128   0 255   0]\n",
      "  [255   0   0   0   0   0   0   0]]]\n",
      "{'ep_rewards': -1094, 'ep_len': 1500, 'move': 293, 'clean': 308, 'turn_left': 325, 'turn_right': 573, 'idle': 1}\n",
      "total steps = 0 | reward = -1094 | length = 1500\n",
      "[[[  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 255   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 128   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [255   0   0 255 255   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [128   0   0   0   0   0   0   0]\n",
      "  [255   0   0   0 128   0   0   0]\n",
      "  [  0   0   0   0 128   0   0   0]\n",
      "  [255   0   0   0   0   0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "    f_net.eval() # let the model know that it in test mode, i.e. no gradient and no dropout\n",
    "    predictions = []\n",
    "    \n",
    "    goal_history, s_Mt_hist, ep_binary = f_net.agent_model_init()\n",
    "    prev_x = env.reset()\n",
    "    print(prev_x)\n",
    "    x = torch.from_numpy(prev_x).float()\n",
    "    step = 0\n",
    "    prev_action = []\n",
    "    \n",
    "    for __ in range(1500):\n",
    "        action_probs, v_Mt, v_Wt, goal_history, s_Mt_hist = f_net(x, goal_history, s_Mt_hist)\n",
    "#         a_t = np.argmax(action_probs.to('cpu').numpy()[0])\n",
    "#         prev_action.append(a_t)\n",
    "#         if prev_action[-5:].count(a_t) == 5:\n",
    "        a_t, _, _ = take_action(action_probs)\n",
    "#                 print('rs')\n",
    "#                 a_t = a_t[0]\n",
    "#         if len(prev_action) > 10:\n",
    "#             prev_action = []\n",
    "# #         print(np.argmax(action_probs.to('cpu').numpy()[0]))\n",
    "\n",
    "#         dist = Categorical(action_probs)\n",
    "#         print(dist.probs)\n",
    "#         action = dist.sample()\n",
    "#         print(action)\n",
    "#         logp = dist.log_prob(action)\n",
    "#         entropy = dist.entropy()\n",
    "        # print('previous:\\n', prev_x)\n",
    "#         x, reward, done, ep_info = env.step(prev_x, a_t)\n",
    "        x, reward, done, ep_info = env.step(prev_x, a_t[0])\n",
    "        \n",
    "        # print('Done\\t:', done)\n",
    "        # print('action:\\t', env.action_meanings[a_t])\n",
    "        # print('post:\\n', x)\n",
    "        # print('-'*50)\n",
    "        if done:\n",
    "            print(f\"total steps = {step} | reward = {ep_info['ep_rewards']} | length = {ep_info['ep_len']}\")\n",
    "            print(x)\n",
    "            break\n",
    "        else:\n",
    "            prev_x = x\n",
    "        x = torch.from_numpy(x).float()\n",
    "        ep = torch.FloatTensor([1.0 - done]).to(device)\n",
    "        # print('EpisodeStatus:\\t', ep)\n",
    "        ep_binary.pop(0)\n",
    "        ep_binary.append(ep)\n",
    "        \n",
    "#         predictions.append(a_t)\n",
    "        predictions.append(a_t[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>action_meanings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turn_right</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turn_left</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>move</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>idle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  action_meanings\n",
       "0  turn_right              572\n",
       "1   turn_left              325\n",
       "2       clean              308\n",
       "3        move              293\n",
       "4        idle                1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.DataFrame.from_dict({'actions': predictions, 'action_meanings':[env.action_meanings[i] for i in predictions]})\n",
    "p['action_meanings'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n",
      "1500\n",
      "[[[  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0 255   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0 128   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0 128   0 128]\n",
      "  [  0   0   0   0   0   0   0   0]\n",
      "  [255   0   0 255 255   0   0   0]\n",
      "  [  0   0   0   0   0 255 128   0]\n",
      "  [128   0   0   0   0   0   0   0]\n",
      "  [255   0   0   0 128 128 255   0]\n",
      "  [  0   0   0 128 128   0 255   0]\n",
      "  [255   0   0   0   0   0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "predictions.append(4)\n",
    "print(len(predictions))\n",
    "print(env_v.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d58bb76372403bb7078b037470aa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', layout=Layout(width='99%'), max=1499), Output()), _d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61a7610aefb497f9a62579b7dbf4d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=320, width=960),), layout=Layout(align_items='center', display='flex', flex_flow=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ac_1 = iter(predictions)\n",
    "ac_2 = iter(predictions)\n",
    "\n",
    "nstate = gu.episode(env_n, lambda _: next(ac_1), max_length=len(predictions))[0]\n",
    "vstate = gu.episode(env_v, lambda _: next(ac_2), max_length=len(predictions))[0]\n",
    "\n",
    "vis = np.concatenate([vstate[:,None,i] for i in [0,1,2]], axis=3)\n",
    "\n",
    "J.images(vis, scale=40, on_interact=list(zip(np.array(env.action_meanings)[predictions],nstate)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
    "\n",
    "# a, b = torch.rand(1, 8), torch.rand(8, 5)\n",
    "\n",
    "# nn.functional.softmax(torch.mm(a, b))\n",
    "\n",
    "# import time\n",
    "\n",
    "# time.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.rand(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
